# Optimizing Inference: Tips from the Field

Deploying models is easy; deploying them efficiently is hard.

## My Checklist
- **FP16 vs INT8**: When to trade precision for speed.
- **Flash Attention**: A game-changer for long context.
- **Speculative Decoding**: How to make big models feel like small ones.

In this post, I share the exact configuration tweaks I use at NeuralCraft.
